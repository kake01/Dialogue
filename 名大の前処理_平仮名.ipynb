{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "名大の前処理_平仮名",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "ffqhJlrBZiIP"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kake01/Dialogue/blob/master/%E5%90%8D%E5%A4%A7%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86_%E5%B9%B3%E4%BB%AE%E5%90%8D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "#名大コーパスの前処理,ベクトル化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aokpp2mfol_C",
        "colab_type": "text"
      },
      "source": [
        "## 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmJsKaBGG8-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install janome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8w9OEi6HGpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 漢字を平仮名に変換するモジュール\n",
        "pip install pykakasi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnxXKDjq3jEL",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import pickle\n",
        "from janome.tokenizer import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gdU8aS_o1lK",
        "colab_type": "text"
      },
      "source": [
        "##データの前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIiKK3KBFkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ファイルの読み込み\n",
        "with open(\"corpus.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "from pykakasi import kakasi\n",
        "\n",
        "seperator = \"。\"  # 。をセパレータに指定\n",
        "sentence_list = text.split(seperator)  # セパレーターを使って文章をリストに分割する\n",
        "sentence_list.pop() # 最後の要素は空の文字列になるので、削除\n",
        "sentence_list = [x+seperator for x in sentence_list]  # 文章の最後に。を追加\n",
        "\n",
        "kakasi = kakasi()\n",
        "kakasi.setMode(\"J\", \"H\")  # J(漢字) からH(ひらがな)へ\n",
        "conv = kakasi.getConverter()\n",
        "# for sentence in sentence_list:\n",
        "#     print(sentence)\n",
        "#     print(conv.do(sentence))\n",
        "#     print()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DuYam6XviES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kana_text = conv.do(text)  # 全体をひらがなに変換\n",
        "print(set(kana_text))  # set()で文字の重複をなくす"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqrWL7dC-dTA",
        "colab_type": "text"
      },
      "source": [
        "###pickleとして保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZZ-0-wKvTJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(kana_text[:500])\n",
        "with open(\"kana_text.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(kana_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieKpTQnjoPhs",
        "colab_type": "text"
      },
      "source": [
        "###辞書の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQnnRwekoMta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "hiragana = \"ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞ\\\n",
        "ただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽ\\\n",
        "まみむめもゃやゅゆょよらりるれろゎわゐゑをん\"\n",
        "\n",
        "katakana = \"ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾ\\\n",
        "タダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポ\\\n",
        "マミムメモャヤュユョヨラリルレロヮワヰヱヲンヴ\"\n",
        "\n",
        "chars = hiragana + katakana\n",
        "\n",
        "with open(\"kana_text.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # 前回保存したファイル\n",
        "    text = f.read()\n",
        "    \n",
        "for char in text:  # ひらがな、カタカナ以外でコーパスに使われている文字を追加\n",
        "    if char not in chars:\n",
        "        chars += char\n",
        "        \n",
        "chars += \"\\t\\n\"  # タブと改行を追加\n",
        "        \n",
        "chars_list = sorted(list(chars))  # 文字列をリストに変換してソートする\n",
        "print(chars_list)\n",
        "\n",
        "with open(\"kana_chars.pickle\", mode=\"wb\") as f:  # pickleで保存\n",
        "    pickle.dump(chars_list, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYzge22jhIcv",
        "colab_type": "text"
      },
      "source": [
        "###encoder,decoderへの入力,decoderの正解を作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiBgjNP7e2Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# インデックスと文字で辞書を作成\n",
        "char_indices = {}  # 文字がキーでインデックスが値\n",
        "for i, char in enumerate(chars_list):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}  # インデックスがキーで文字が値\n",
        "for i, char in enumerate(chars_list):\n",
        "    indices_char[i] = char\n",
        "    \n",
        "seperator = \"。\"\n",
        "sentence_list = text.split(seperator) \n",
        "sentence_list.pop() \n",
        "sentence_list = [x+seperator for x in sentence_list]\n",
        "\n",
        "max_sentence_length = 128  # 文章の最大長さ。これより長い文章はカットされる。\n",
        "sentence_list = [sentence for sentence in sentence_list if len(sentence) <= max_sentence_length]  # 長すぎる文章のカット\n",
        "\n",
        "n_char = len(chars_list)  # 文字の種類の数\n",
        "n_sample = len(sentence_list) - 1  # サンプル数\n",
        "\n",
        "x_sentences = []  # 入力の文章\n",
        "t_sentences = []  # 正解の文章\n",
        "for i in range(n_sample):\n",
        "    x_sentences.append(sentence_list[i])\n",
        "    t_sentences.append(\"\\t\" + sentence_list[i+1] + \"\\n\")  # 正解は先頭にタブ、末尾に改行を加える\n",
        "max_length_x = max_sentence_length  # 入力文章の最大長さ\n",
        "max_length_t = max_sentence_length + 2  # 正解文章の最大長さ\n",
        "\n",
        "x_encoder = np.zeros((n_sample, max_length_x, n_char), dtype=np.bool)  # encoderへの入力\n",
        "x_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderへの入力\n",
        "t_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderの正解\n",
        "\n",
        "for i in range(n_sample):\n",
        "    x_sentence = x_sentences[i]\n",
        "    t_sentence = t_sentences[i]\n",
        "    for j, char in enumerate(x_sentence):\n",
        "        x_encoder[i, j, char_indices[char]] = 1  # encoderへの入力をone-hot表現で表す\n",
        "    for j, char in enumerate(t_sentence):\n",
        "        x_decoder[i, j, char_indices[char]] = 1  # decoderへの入力をone-hot表現で表す\n",
        "        if j > 0:  # 正解は入力より1つ前の時刻のものにする\n",
        "            t_decoder[i, j-1, char_indices[char]] = 1\n",
        "            \n",
        "print(x_encoder.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udPly_pGYoLV",
        "colab_type": "text"
      },
      "source": [
        "##学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e86Z78NCXn01",
        "colab_type": "text"
      },
      "source": [
        "###学習モデルの構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AryXwmD4SbmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 50\n",
        "n_mid = 500  # 中間層のニューロン数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzUQxkPTjId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GRU, Input, Masking\n",
        "\n",
        "encoder_input = Input(shape=(None, n_char))\n",
        "encoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
        "encoder_masked = encoder_mask(encoder_input)\n",
        "encoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_state=True)  # dropoutを設定し、ニューロンをランダムに無効にする\n",
        "encoder_output, encoder_state_h = encoder_lstm(encoder_masked)\n",
        "\n",
        "decoder_input = Input(shape=(None, n_char))\n",
        "decoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
        "decoder_masked = decoder_mask(decoder_input)\n",
        "decoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True)  # dropoutを設定\n",
        "decoder_output, _ = decoder_lstm(decoder_masked, initial_state=encoder_state_h)  # encoderの状態を初期状態にする\n",
        "decoder_dense = Dense(n_char, activation='softmax')\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "model = Model([encoder_input, decoder_input], decoder_output)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOASGGpaTmle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "# val_lossに改善が見られなくなってから、30エポックで学習は終了\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=30) \n",
        "\n",
        "history = model.fit([x_encoder, x_decoder], t_decoder,\n",
        "                     batch_size=batch_size,\n",
        "                     epochs=epochs,\n",
        "                     validation_split=0.1,  # 10%は検証用\n",
        "                     callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG7TgJLOYzH5",
        "colab_type": "text"
      },
      "source": [
        "### 学習の推移\n",
        "誤差の推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7VvJWI-To8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(np.arange(len(loss)), loss,label=\"seikai\")\n",
        "plt.plot(np.arange(len(val_loss)), val_loss, label=\"sa\")\n",
        "plt.\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffqhJlrBZiIP",
        "colab_type": "text"
      },
      "source": [
        "### 予測用モデルの構築,保存\n",
        "学習済みのオブジェクトから、encoder、decoderのモデルを個別に構築。    \n",
        "encoderは入力を受け取って状態を返し、decoderは入力と状態を受け取って出力と状態を返す。\n",
        "それ以外は不要なので保存しない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfPWbRz1Ziep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoderのモデル\n",
        "encoder_model = Model(encoder_input, encoder_state_h)\n",
        "\n",
        "# decoderのモデル\n",
        "decoder_state_in_h = Input(shape=(n_mid,))\n",
        "decoder_state_in = [decoder_state_in_h]\n",
        "\n",
        "decoder_output, decoder_state_h = decoder_lstm(decoder_input,\n",
        "                                               initial_state=decoder_state_in_h)\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "decoder_model = Model([decoder_input] + decoder_state_in,\n",
        "                      [decoder_output, decoder_state_h])\n",
        "\n",
        "# モデルの保存\n",
        "encoder_model.save('encoder_model.h5')\n",
        "decoder_model.save('decoder_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6FDMJf4Z775",
        "colab_type": "text"
      },
      "source": [
        "## 返答作成用の関数\n",
        "encoderのモデル、およびdecoderのモデルを読み込み、返答を作成するための関数を設定します。  \n",
        "関数のコードは前のセクションで扱ったものと同じですが、引数を文字列で受け取る点が異なります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fieakPQge6I",
        "colab_type": "text"
      },
      "source": [
        "### 文字の読み込み\n",
        "使用する文字を読み込みます。  \n",
        "また、使用できない文字が含まれているかどうか、判定する関数を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcpA-LyQfha_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_invalid(message):\n",
        "    is_invalid =False\n",
        "    for char in message:\n",
        "        if char not in chars_list:\n",
        "            is_invalid = True\n",
        "    return is_invalid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl1nUC09graK",
        "colab_type": "text"
      },
      "source": [
        "###辞書とベクトル化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVNCvsygfn_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# インデックスと文字で辞書を作成\n",
        "char_indices = {}\n",
        "for i, char in enumerate(chars_list):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}\n",
        "for i, char in enumerate(chars_list):\n",
        "    indices_char[i] = char\n",
        "    \n",
        "n_char = len(chars_list)\n",
        "max_length_x = 128\n",
        "\n",
        "# 文章をone-hot表現に変換する関数\n",
        "def sentence_to_vector(sentence):\n",
        "    vector = np.zeros((1, max_length_x, n_char), dtype=np.bool)\n",
        "    for j, char in enumerate(sentence):\n",
        "        vector[0][j][char_indices[char]] = 1\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUKFoZwLaso6",
        "colab_type": "text"
      },
      "source": [
        "## チャットボットの構築\n",
        "resopond関数を使って、チャットボットのシステムを構築します。  \n",
        "ひらがな、カタカナと一部の記号以外の文字が入力された場合は、注意を表示するようにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_vf1UGEZ8LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "encoder_model = load_model('encoder_model.h5')\n",
        "decoder_model = load_model('decoder_model.h5')\n",
        "\n",
        "def respond(message, beta=5):\n",
        "    vec = sentence_to_vector(message)  # 文字列をone-hot表現に変換\n",
        "    state_value = encoder_model.predict(vec)\n",
        "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
        "    y_decoder[0][0][char_indices['\\t']] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
        "\n",
        "    respond_sentence = \"\"  # 返答の文字列\n",
        "    while True:\n",
        "        y, h = decoder_model.predict([y_decoder, state_value])\n",
        "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
        "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
        "        next_char = indices_char[next_index]  # 次の文字\n",
        "        \n",
        "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
        "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
        "            \n",
        "        respond_sentence += next_char\n",
        "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
        "        y_decoder[0][0][next_index] = 1\n",
        "\n",
        "        state_value = h  # 次の時刻の状態\n",
        "\n",
        "    return respond_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaVJ8vyhg0Fs",
        "colab_type": "text"
      },
      "source": [
        "##Botと人類の対話"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tx1UzV0awOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot_name = \"bot\"\n",
        "your_name = input(\"おなまえをおしえてください。:\")\n",
        "print()\n",
        "\n",
        "print(bot_name + \": \" + \"こんにちは、\" + your_name + \"さん。\")\n",
        "message = \"\"\n",
        "while message != \"さようなら。\":\n",
        "    \n",
        "    while True:\n",
        "        message = input(your_name + \": \")\n",
        "        if not is_invalid(message):\n",
        "            break\n",
        "        else:\n",
        "            print(bot_name + \": ひらがなか、カタカナをつかってください。\")\n",
        "            \n",
        "    response = respond(message)\n",
        "    print(bot_name + \": \" + response)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}