{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "名古屋大学の前処理",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "D1Tes2Wy-S_6"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kake01/Dialogue/blob/master/%E5%90%8D%E5%8F%A4%E5%B1%8B%E5%A4%A7%E5%AD%A6%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "#名古屋大コーパスの前処理,ベクトル化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aokpp2mfol_C",
        "colab_type": "text"
      },
      "source": [
        "## 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAAOeaNrOz39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# janomeのインストール\n",
        "pip install janome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnxXKDjq3jEL",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import pickle\n",
        "from janome.tokenizer import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## データセットの解凍と前処理と保存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBUNA8MttoPY",
        "colab_type": "text"
      },
      "source": [
        "###データの解凍"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9u9aSW2jrfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile('data.zip') as existing_zip:\n",
        "  existing_zip.extractall('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gdU8aS_o1lK",
        "colab_type": "text"
      },
      "source": [
        "###データの前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRVATYOgJs1b",
        "colab": {}
      },
      "source": [
        "text = \"\"\n",
        "\n",
        "# s = \"私は柴犬【しばいぬ】とシャム猫【しゃむねこ】が大好きです。\"\n",
        "# s = re.sub(\"【[^】]+】\", \"\", s)  # 【と】の間に】以外の文字が複数ある箇所を、空の文字列に置き換える\n",
        "for data_num in range(129):\n",
        "  with open(\"data/nucc/data_\"+str(data_num+1)+\".txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
        "    texts = f.read()\n",
        "  texts = re.sub(\"《[^》]+》\", \"\", texts)  # ルビの削除\n",
        "  texts = re.sub(\"［[^］]+］\", \"\", texts)  # 読みの注意の削除\n",
        "  texts = re.sub(\"〔[^〕]+〕\", \"\", texts)  # 読みの注意の削除\n",
        "\n",
        "# オリジナル部分\n",
        "  texts = re.sub(\"＜[^＞]+＞\", \"\", texts)  # ＜笑い＞の削除\n",
        "  texts = re.sub(\"＠[^\\n]+\\n\", \"\", texts)  # @から始まる文を削除\n",
        "\n",
        "  texts = re.sub(\"F[^：]+：\", \"\", texts)   # 誰が喋ったかの名前削除\n",
        "  texts = re.sub(\"M[^：]+：\", \"\", texts)   # 誰が喋ったかの名前削除\n",
        "\n",
        "  texts = re.sub(\"[ 　\\n「」『』（）｜※＊…]\", \"\", texts)  # 全角半角スペース、改行、その他記号の削除\n",
        "  text += texts\n",
        "\n",
        "print(\"文字数:\", len(text))\n",
        "print(text[:90])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6YQ_fnjAREf",
        "colab_type": "text"
      },
      "source": [
        "###データの保存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Tes2Wy-S_6",
        "colab_type": "text"
      },
      "source": [
        "####.txtとして保存\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SY7WsJQ_3Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# コーパスとして保存する\n",
        "with open(\"corpus.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqrWL7dC-dTA",
        "colab_type": "text"
      },
      "source": [
        "####.pickleとして保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIiKK3KBFkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ファイルの読み込み\n",
        "with open(\"corpus.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "seperator = \"。\"  # 。をセパレータに指定\n",
        "sentence_list = text.split(seperator)  # セパレーターを使って文章をリストに分割する\n",
        "sentence_list.pop() # 最後の要素は空の文字列になるので、削除\n",
        "sentence_list = [x+seperator for x in sentence_list]  # 文章の最後に。を追加\n",
        "\n",
        "\n",
        "\n",
        "t = Tokenizer()\n",
        "\n",
        "words = []\n",
        "for sentence in sentence_list:\n",
        "    words.append(t.tokenize(sentence, wakati=True))   # 文章ごとに単語に分割し、リストに格納\n",
        "    \n",
        "with open('words.pickle', mode='wb') as f:  # pickleに保存\n",
        "    pickle.dump(words, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRsjOTIT-N55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('words.pickle', mode='rb') as f:\n",
        "    wagahai_words = pickle.load(f)\n",
        "print(wagahai_words[:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAS0B9AH_KYX",
        "colab_type": "text"
      },
      "source": [
        "##単語のベクトル化(word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x1cAJJc_aI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "# size : 中間層のニューロン数\n",
        "# min_count : この値以下の出現回数の単語を無視\n",
        "# window : 対象単語を中心とした前後の単語数\n",
        "# iter : epochs数\n",
        "# sg : skip-gramを使うかどうか 0:CBOW 1:skip-gram\n",
        "model = word2vec.Word2Vec(wagahai_words,\n",
        "                          size=100,\n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          iter=20,\n",
        "                          sg = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3XnNSbz_rep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.wv.vectors.shape)  # 分散表現の形状\n",
        "print(model.wv.vectors)  # 分散表現"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiQQ-c-5_5fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.wv.most_similar(\"怖い\"))  # 最も似ている単語"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PRZdSiYdFLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # モデルを保存\n",
        "# model.save(\"model.model\")\n",
        "# # モデルを読み込む\n",
        "# model = word2vec.Word2Vec.load(\"model.model\")\n",
        "\n",
        "with open('model.pickle', mode='wb') as f:  # pickleに保存\n",
        "    pickle.dump(model.wv.vectors, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiBgjNP7e2Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}